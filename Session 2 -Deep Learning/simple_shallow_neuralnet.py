# -*- coding: utf-8 -*-
"""Simple_Shallow_NeuralNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/117bO5uQKC4f6lzIe9q6eBeyn_65zOXeh

# Shallow Neural Network in TensorFlow

Build a shallow neural network to classify handwritten digits

#### Load dependencies
"""

import tensorflow
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
from matplotlib import pyplot as plt
import numpy as np

"""#### Load data"""

(X_train, y_train), (X_valid, y_valid) = mnist.load_data()

X_train.shape

y_train.shape

y_train[0:12]

plt.figure(figsize=(5,5))
for k in range(12):
    plt.subplot(3, 4, k+1)
    plt.imshow(X_train[k], cmap='Greys')
    plt.axis('off')
plt.tight_layout()
plt.show()

X_valid.shape

y_valid.shape

_ = plt.imshow(X_valid[0], cmap='Greys')

X_valid[0]

y_valid[0]

"""#### Preprocess data"""

X_train = X_train.reshape(60000, 784).astype('float32')
X_valid = X_valid.reshape(10000, 784).astype('float32')



X_train /= 255
X_valid /= 255

X_valid[0]

n_classes = 10
y_train = to_categorical(y_train, n_classes)
y_valid = to_categorical(y_valid, n_classes)

y_valid[0]

"""#### Design neural network architecture"""

model = Sequential()
model.add(Dense(64, activation='sigmoid', input_shape=(784,)))
model.add(Dense(10, activation='softmax'))

model.summary()

(64*784)

(64*784)+64

(10*64)+10

"""#### Configure model"""

model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Train!"""

model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_valid, y_valid))

"""#### Evaluating model performance"""

model.evaluate(X_valid, y_valid)

"""#### Performing inference"""

valid_0 = X_valid[0].reshape(1, 784)

y_predicted = model.predict(X_valid)
y_predicted[0]

y_predicted_labels = [np.argmax(i) for i in y_predicted]

# model.predict_classes(valid_0)

# Convert y_valid back to class indices for confusion matrix
y_valid_labels = np.argmax(y_valid, axis=1)
cm = tensorflow.math.confusion_matrix(labels=y_valid_labels, predictions=y_predicted_labels)
cm

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

model.get_weights()

"""saved_model.pb: This is the main Protocol Buffer file that contains the TensorFlow graph definition, including the model's architecture, operations, and a set of named signatures that define the model's callable functions.
variables/: This directory stores the model's learned parameters (weights and biases).
assets/: This optional directory can store auxiliary files used by the model, such as vocabulary files or lookup tables
"""

model.export("./saved_model")

converter = tensorflow.lite.TFLiteConverter.from_saved_model("./saved_model")
tflite_model = converter.convert()

converter = tensorflow.lite.TFLiteConverter.from_saved_model("./saved_model")
converter.optimizations = [tensorflow.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()

len(tflite_model)

len(tflite_quant_model)

import tensorflow_model_optimization as tfmot

quantize_model = tfmot.quantization.keras.quantize_model

# q_aware stands for for quantization aware.
q_aware_model = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

q_aware_model.summary()

"""# TensorBoard"""

tb_callback = tensorflow.keras.callbacks.TensorBoard(log_dir="logs/sdm", histogram_freq=1)

model.fit(X_train, y_train, epochs=5, callbacks=[tb_callback])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

