# -*- coding: utf-8 -*-
"""GpuVsCpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hiwvpYhQPyx8q4-fyM63736RXeg_OQ4j

<h2 style='color:blue'>Small Image Classification Using Simple Aritifical Neural Network: GPU Benchmarking</h2>
"""

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
# Version Information
# tensorflow 2.2.0 , Cudnn7.6.5 and Cuda 10.1 , python 3.8

"""**This command shows list of physical devices available for tensorflow. You can see GPU listed here. If you have NVIDIA GPU you need to install CUDA toolkit and cuDNN as per instruction on this webpage. Without proper installation you will not see GPU in list of devices**

https://shawnhymel.com/1961/how-to-install-tensorflow-with-gpu-support-on-windows/
"""

tf.config.experimental.list_physical_devices()

tf.__version__

tf.test.is_built_with_cuda()

"""<h4 style="color:purple">Load the dataset</h4>

Our dataset contains 60000 small training images that belongs to one of the below 10 classes

<img src="small_images.jpg" />
"""

(X_train, y_train), (X_test,y_test) = tf.keras.datasets.cifar10.load_data()

X_train.shape

y_train.shape

"""<h4 style="color:purple">Data Visualization</h4>"""

def plot_sample(index):
    plt.figure(figsize = (10,1))
    plt.imshow(X_train[index])

plot_sample(0)

plot_sample(1)

plot_sample(2)

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

plot_sample(3)

classes[y_train[3][0]]

y_train[:3]

y_test.shape

X_train.shape

"""<h4 style="color:purple">Preprocessing: Scale images</h4>"""

X_train_scaled = X_train / 255
X_test_scaled = X_test / 255

y_train_categorical = keras.utils.to_categorical(
    y_train, num_classes=10
)
y_test_categorical = keras.utils.to_categorical(
    y_test, num_classes=10
)

y_train[0:5]

y_train_categorical[0:5]

"""<h4 style="color:purple">Model building and training</h4>"""

model = keras.Sequential([
        keras.layers.Flatten(input_shape=(32,32,3)),
        keras.layers.Dense(3000, activation='relu'),
        keras.layers.Dense(1000, activation='relu'),
        keras.layers.Dense(10, activation='sigmoid')
    ])

model.compile(optimizer='SGD',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(X_train_scaled, y_train_categorical, epochs=1)

"""<h4 style="color:purple">Let's make some predictions</h4>"""

np.argmax(model.predict(X_test_scaled)[0])

y_test[0]

def get_model():
    model = keras.Sequential([
            keras.layers.Flatten(input_shape=(32,32,3)),
            keras.layers.Dense(3000, activation='relu'),
            keras.layers.Dense(1000, activation='relu'),
            keras.layers.Dense(10, activation='sigmoid')
        ])

    model.compile(optimizer='SGD',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

"""<h3 style='color:purple'>Measure training time on a CPU<h3>"""

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r1
# with tf.device('/CPU:0'):
#     cpu_model = get_model()
#     cpu_model.fit(X_train_scaled, y_train_categorical, epochs=1)

"""<h3 style='color:purple'>Lets measure training time on a GPU ( Nvidia T4)<h3>"""

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r1
# with tf.device('/GPU:0'):
#     cpu_model = get_model()
#     cpu_model.fit(X_train_scaled, y_train_categorical, epochs=1)

"""<h3 style='color:purple'>Lets run same test for 10 epocs<h3>"""

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r1
# with tf.device('/CPU:0'):
#     cpu_model = get_model()
#     cpu_model.fit(X_train_scaled, y_train_categorical, epochs=10)

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r1
# with tf.device('/GPU:0'):
#     cpu_model = get_model()
#     cpu_model.fit(X_train_scaled, y_train_categorical, epochs=10)

from google.colab import drive
drive.mount('/content/drive')

"""Here is the performance comparison for 1 epoch,

| Epoch | CPU | GPU  |
|:------|:------|:------|
| 1 | 43 sec | 3 sec |
| 10 | 7 min 26 sec | 30 sec |

You can see that GPU is almost 15 times faster. We ran only one epoch for benchmarking but for actual training we have to run many epochs and also when data volume is big running deep learning without GPU can consume so much time. This is the reason why GPUs are becoming popular in the field of deep learning
"""