{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üéì LangGraph RAG System - Teaching Notebook\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn:\n",
    "\n",
    "1. ‚úÖ How to connect to Milvus vector database using LangChain\n",
    "2. ‚úÖ How to create retrievers with metadata filtering\n",
    "3. ‚úÖ How to build a complete RAG pipeline with LangGraph\n",
    "4. ‚úÖ How to integrate NetApp's internal LLM endpoint\n",
    "5. ‚úÖ How to visualize and test the workflow\n",
    "\n",
    "## System Overview\n",
    "\n",
    "**Data Source:** 1,037 pages from 20 SEC filing PDFs (5 companies: AAPL, AMZN, INTC, MSFT, NVDA)\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Question ‚Üí Embedding ‚Üí Milvus Search ‚Üí Retrieve Docs ‚Üí NetApp LLM ‚Üí Answer\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- ‚úÖ Milvus running at 127.0.0.1:19530\n",
    "- ‚úÖ Collection `sec_filings` loaded with data\n",
    "- ‚úÖ Required packages installed (`pip install -r requirements.txt`)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 1: Setup and Configuration\n",
    "\n",
    "### üìù Instructions:\n",
    "**IMPORTANT:** Run this cell first to reset SSL settings and import packages.\n",
    "\n",
    "### What this cell does:\n",
    "- Clears any old SSL environment variables from previous runs\n",
    "- Imports all required packages\n",
    "- Sets Milvus connection parameters  \n",
    "- Defines embedding model (MUST match SECRag.ipynb)\n",
    "\n",
    "### Note:\n",
    "This fixes TLS/certificate errors by clearing old environment variable settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca9af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n",
      "üìä Config: 127.0.0.1:19530, collection: sec_filings\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Clear any old SSL environment variables from previous runs\n",
    "for env_var in ['REQUESTS_CA_BUNDLE', 'SSL_CERT_FILE', 'CURL_CA_BUNDLE']:\n",
    "    if env_var in os.environ:\n",
    "        del os.environ[env_var]\n",
    "        print(f\"üßπ Cleared old {env_var}\")\n",
    "\n",
    "# Configuration\n",
    "MILVUS_HOST = \"127.0.0.1\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "COLLECTION_NAME = \"sec_filings\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"  # Same as SECRag.ipynb\n",
    "\n",
    "print(\"‚úÖ Imports complete\")\n",
    "print(f\"üìä Config: {MILVUS_HOST}:{MILVUS_PORT}, collection: {COLLECTION_NAME}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 2: Load Embedding Model\n",
    "\n",
    "### üìù Instructions:\n",
    "Load the SentenceTransformer model (same as SECRag.ipynb).\n",
    "\n",
    "### What this does:\n",
    "- Loads `all-MiniLM-L6-v2` model (384 dimensions)\n",
    "- First run: downloads from HuggingFace (~90MB, 1-2 min)\n",
    "- Subsequent runs: loads from cache (instant)\n",
    "- Uses standard SSL (no modifications needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc3f06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading model: all-MiniLM-L6-v2...\n",
      "‚úÖ Model loaded: all-MiniLM-L6-v2\n",
      "   Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load SentenceTransformer model (same as SECRag.ipynb)\n",
    "print(f\"üì• Loading model: {EMBED_MODEL}...\")\n",
    "\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "DIM = embedder.get_sentence_embedding_dimension()\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {EMBED_MODEL}\")\n",
    "print(f\"   Dimension: {DIM}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7107e9b0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 3: Create Custom Embedding Function\n",
    "\n",
    "### üìù Instructions:\n",
    "Create a custom embedding function for Milvus (same approach as SECRag).\n",
    "\n",
    "### Why this approach:\n",
    "- Uses SentenceTransformer directly (no HuggingFace wrapper)\n",
    "- Same method as used for indexing\n",
    "- `normalize_embeddings=True` matches SECRag.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0970085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom embedding function created\n",
      "   Uses: SentenceTransformer (same as SECRag.ipynb)\n",
      "   Normalization: True\n"
     ]
    }
   ],
   "source": [
    "# Create custom embedding function (same as SECRag approach)\n",
    "class SentenceTransformerEmbeddings:\n",
    "    \"\"\"Custom embedding function using SentenceTransformer directly\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embed a list of documents\"\"\"\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embed a single query\"\"\"\n",
    "        return self.model.encode([text], normalize_embeddings=True)[0].tolist()\n",
    "\n",
    "# Create embeddings object\n",
    "embeddings = SentenceTransformerEmbeddings(embedder)\n",
    "\n",
    "print(f\"‚úÖ Custom embedding function created\")\n",
    "print(f\"   Uses: SentenceTransformer (same as SECRag.ipynb)\")\n",
    "print(f\"   Normalization: True\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 4: Connect to Milvus\n",
    "\n",
    "### üìù Instructions:\n",
    "Connect to the existing Milvus collection.\n",
    "\n",
    "### Key parameters:\n",
    "- `embedding_function`: Converts text to vectors\n",
    "- `collection_name`: The collection we created in SECRag.ipynb\n",
    "- `text_field`: Field storing document text\n",
    "- `vector_field`: Field storing embeddings\n",
    "- `auto_id=True`: We used auto IDs during indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd7c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Milvus: sec_filings\n",
      "   Host: 127.0.0.1:19530\n"
     ]
    }
   ],
   "source": [
    "# Connect to Milvus\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT},\n",
    "    text_field=\"text\",\n",
    "    vector_field=\"embedding\",\n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to Milvus: {COLLECTION_NAME}\")\n",
    "print(f\"   Host: {MILVUS_HOST}:{MILVUS_PORT}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 5: Test Basic Retrieval\n",
    "\n",
    "### üìù Instructions:\n",
    "Test simple retrieval to verify the connection works.\n",
    "\n",
    "### What happens:\n",
    "1. Question is converted to a 384-dim vector\n",
    "2. Milvus finds 5 most similar documents\n",
    "3. Results include metadata (company, year, quarter, page)\n",
    "\n",
    "### Observe:\n",
    "- Which documents are retrieved\n",
    "- Relevance to the question  \n",
    "- Available metadata fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d81cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 5 documents\\n\n",
      "1. 2022 Q3 AMZN.pdf (Page 27)\n",
      "   AMZN Q3 2022\n",
      "   Preview: Table of Contents\n",
      "While costs associated with Amazon Prime membership benefits and other shipping offers are not included in sales and marketing expen...\\n\n",
      "2. 2023 Q2 AMZN.pdf (Page 3)\n",
      "   AMZN Q2 2023\n",
      "   Preview: Table of Contents\n",
      "AMAZON.COM, INC.\n",
      "CONSOLIDATED STATEMENTS OF OPERATIONS\n",
      "(in millions, except per share data)\n",
      "(unaudited)\n",
      "  Three Months EndedJune 30,...\\n\n",
      "3. 2023 Q3 AMZN.pdf (Page 3)\n",
      "   AMZN Q3 2023\n",
      "   Preview: Table of Contents\n",
      "AMAZON.COM, INC.\n",
      "CONSOLIDATED STATEMENTS OF OPERATIONS\n",
      "(in millions, except per share data)\n",
      "(unaudited)\n",
      "  Three Months EndedSeptembe...\\n\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "docs = retriever.invoke(\"What was Amazon's revenue in Q1 2023?\")\n",
    "\n",
    "print(f\"‚úÖ Retrieved {len(docs)} documents\\\\n\")\n",
    "for i, doc in enumerate(docs[:3], 1):\n",
    "    print(f\"{i}. {doc.metadata.get('filename')} (Page {doc.metadata.get('page')})\")\n",
    "    print(f\"   {doc.metadata.get('company')} {doc.metadata.get('quarter')} {doc.metadata.get('year')}\")\n",
    "    print(f\"   Preview: {doc.page_content[:150]}...\\\\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 6: Configure NetApp LLM\n",
    "\n",
    "### üìù Instructions:\n",
    "Set up connection to NetApp's internal LLM endpoint.\n",
    "\n",
    "### Configuration includes:\n",
    "- API endpoint URL (`/v1/completions`)\n",
    "- Authentication token (Bearer format)\n",
    "- User ID and model name\n",
    "- SSL fix for self-signed certificates\n",
    "\n",
    "### Security note:\n",
    "We disable SSL verification for NetApp's internal endpoint (safe for corporate networks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f82498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NetApp LLM configured\n",
      "   Endpoint: https://llm-proxy-api.ai.eng.netapp.com/v1/completions\n",
      "   Model: gpt-5, User: pg47711\n"
     ]
    }
   ],
   "source": [
    "# NetApp LLM Configuration\n",
    "NETAPP_LLM_ENDPOINT = \"https://llm-proxy-api.ai.eng.netapp.com/v1/completions\"\n",
    "NETAPP_API_KEY = \"sk_54508d6938935f6e4472170ee0d5beb05e725e91d3da9f0effb48c60e902960d\"\n",
    "NETAPP_USER = \"pg47711\"\n",
    "NETAPP_MODEL = \"gpt-5\"\n",
    "\n",
    "# SSL Fix for self-signed certificates\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "print(\"‚úÖ NetApp LLM configured\")\n",
    "print(f\"   Endpoint: {NETAPP_LLM_ENDPOINT}\")\n",
    "print(f\"   Model: {NETAPP_MODEL}, User: {NETAPP_USER}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 7: Test LLM Connection\n",
    "\n",
    "### üìù Instructions:\n",
    "Verify NetApp LLM is accessible.\n",
    "\n",
    "### Expected result:\n",
    "- ‚úÖ Status 200\n",
    "- Response shows: `{\"choices\":[{\"text\":\"4\"}]}`\n",
    "- Answer location: `response[\"choices\"][0][\"text\"]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82825019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM Working! Answer: '4'\n",
      "   Answer location: response['choices'][0]['text']\n"
     ]
    }
   ],
   "source": [
    "# Test NetApp LLM\n",
    "response = requests.post(\n",
    "    NETAPP_LLM_ENDPOINT,\n",
    "    headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {NETAPP_API_KEY}\"},\n",
    "    json={\"model\": NETAPP_MODEL, \"user\": NETAPP_USER, \"prompt\": \"What is 2+2?\"},\n",
    "    verify=False,\n",
    "    timeout=10\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    answer = response.json()[\"choices\"][0][\"text\"]\n",
    "    print(f\"‚úÖ LLM Working! Answer: '{answer}'\")\n",
    "    print(f\"   Answer location: response['choices'][0]['text']\")\n",
    "else:\n",
    "    print(f\"‚ùå Error {response.status_code}: {response.text[:100]}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 8: Define RAG State\n",
    "\n",
    "### üìù Instructions:\n",
    "Define the state structure for the LangGraph workflow.\n",
    "\n",
    "### What is state?\n",
    "- A container that flows through the workflow\n",
    "- Each node reads from and writes to it\n",
    "- Accumulates information at each step\n",
    "\n",
    "### State fields:\n",
    "- `question`: User's input\n",
    "- `context`: Retrieved documents (from retrieve node)\n",
    "- `answer`: LLM output (from generate node)\n",
    "- `metadata_filter`: Optional filter\n",
    "- `retrieved_count`: Tracking info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebd52228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG State defined with 5 fields\n"
     ]
    }
   ],
   "source": [
    "# Define RAG State\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    metadata_filter: str\n",
    "    retrieved_count: int\n",
    "\n",
    "print(\"‚úÖ RAG State defined with 5 fields\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 9: Create Retrieval Node\n",
    "\n",
    "### üìù Instructions:\n",
    "Define the first LangGraph node - retrieves documents from Milvus.\n",
    "\n",
    "### Node function pattern:\n",
    "- Input: Current state\n",
    "- Process: Query Milvus with optional filter\n",
    "- Output: Updated state with documents\n",
    "\n",
    "### This node:\n",
    "1. Extracts question and filter from state\n",
    "2. Creates retriever with filter\n",
    "3. Queries Milvus\n",
    "4. Returns state + retrieved docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4de4427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieval node defined\n"
     ]
    }
   ],
   "source": [
    "# Retrieval Node\n",
    "def retrieve_documents(state: RAGState) -> RAGState:\n",
    "    question = state[\"question\"]\n",
    "    metadata_filter = state.get(\"metadata_filter\", \"\")\n",
    "    \n",
    "    print(f\"\\\\nüîç Retrieving for: '{question}'\")\n",
    "    if metadata_filter:\n",
    "        print(f\"   Filter: {metadata_filter}\")\n",
    "    \n",
    "    # Create retriever with optional filter\n",
    "    search_kwargs = {\"k\": 5}\n",
    "    if metadata_filter:\n",
    "        search_kwargs[\"expr\"] = metadata_filter\n",
    "    \n",
    "    temp_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    \n",
    "    docs = temp_retriever.invoke(question)\n",
    "    print(f\"   ‚úÖ Retrieved {len(docs)} documents\")\n",
    "    \n",
    "    for i, doc in enumerate(docs[:3], 1):\n",
    "        print(f\"   {i}. {doc.metadata.get('filename')} (Page {doc.metadata.get('page')})\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"context\": docs,\n",
    "        \"metadata_filter\": metadata_filter,\n",
    "        \"retrieved_count\": len(docs),\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Retrieval node defined\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 10: Create Generation Node\n",
    "\n",
    "### üìù Instructions:\n",
    "Define the second node - generates answers using NetApp LLM.\n",
    "\n",
    "### This node:\n",
    "1. Formats context from top 3 docs (500 chars each)\n",
    "2. Creates prompt (instructions + question + context)\n",
    "3. Calls NetApp LLM API\n",
    "4. Parses response: `response[\"choices\"][0][\"text\"]`\n",
    "5. Returns state + answer\n",
    "\n",
    "### API format:\n",
    "```python\n",
    "POST /v1/completions\n",
    "Headers: {\"Authorization\": \"Bearer {key}\"}\n",
    "Body: {\"model\": \"gpt-5\", \"user\": \"pg47711\", \"prompt\": \"...\"}\n",
    "Response: {\"choices\": [{\"text\": \"answer\"}]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9092956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generation node defined\n"
     ]
    }
   ],
   "source": [
    "# Generation Node\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    question = state[\"question\"]\n",
    "    context_docs = state[\"context\"]\n",
    "    \n",
    "    print(f\"\\\\nüí° Generating answer...\")\n",
    "    \n",
    "    # Format context\n",
    "    context_text = \"\\\\n\\\\n\".join([\n",
    "        f\"[{doc.metadata.get('filename')}, Page {doc.metadata.get('page')}]\\\\n{doc.page_content[:500]}\"\n",
    "        for doc in context_docs[:3]\n",
    "    ])\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"You are an assistant for question-answering tasks. Use the retrieved context to answer the question. If you don't know, say so. Max 3 sentences, keep it concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call NetApp LLM\n",
    "        response = requests.post(\n",
    "            NETAPP_LLM_ENDPOINT,\n",
    "            headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {NETAPP_API_KEY}\"},\n",
    "            json={\"model\": NETAPP_MODEL, \"user\": NETAPP_USER, \"prompt\": prompt},\n",
    "            timeout=60,\n",
    "            verify=False\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            answer = response.json()[\"choices\"][0][\"text\"].strip()\n",
    "            print(f\"   ‚úÖ Answer received ({len(answer)} chars)\")\n",
    "        else:\n",
    "            answer = f\"API Error ({response.status_code}): {response.text[:100]}\"\n",
    "            print(f\"   ‚ùå {answer}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        answer = f\"Error: {str(e)[:100]}\\\\n\\\\nContext: {context_text[:300]}...\"\n",
    "        print(f\"   ‚ùå {str(e)[:50]}\")\n",
    "    \n",
    "    return {**state, \"answer\": answer}\n",
    "\n",
    "print(\"‚úÖ Generation node defined\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 11: Build LangGraph Workflow\n",
    "\n",
    "### üìù Instructions:\n",
    "Connect the nodes to create the complete RAG workflow.\n",
    "\n",
    "### Workflow:\n",
    "```\n",
    "START ‚Üí retrieve ‚Üí generate ‚Üí END\n",
    "```\n",
    "\n",
    "### How it works:\n",
    "1. Call `app.invoke({...})` with initial state\n",
    "2. Execute `retrieve` node (get docs from Milvus)\n",
    "3. Execute `generate` node (get answer from LLM)\n",
    "4. Return final state with answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f185621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Workflow compiled: START ‚Üí retrieve ‚Üí generate ‚Üí END\n"
     ]
    }
   ],
   "source": [
    "# Build workflow\n",
    "workflow = StateGraph(RAGState)\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Workflow compiled: START ‚Üí retrieve ‚Üí generate ‚Üí END\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 12: Visualize Workflow\n",
    "\n",
    "### üìù Instructions:\n",
    "Generate a visual diagram of the RAG pipeline.\n",
    "\n",
    "### Benefits:\n",
    "- Easy to understand system architecture\n",
    "- Great for explaining to stakeholders  \n",
    "- Helps identify optimization opportunities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb8ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Diagram displayed above\n"
     ]
    }
   ],
   "source": [
    "# Visualize workflow\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "    print(\"‚úÖ Diagram displayed above\")\n",
    "except:\n",
    "    print(\"START ‚Üí retrieve ‚Üí generate ‚Üí END\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Testing the Complete RAG System\n",
    "\n",
    "## Test 1: Basic Query (No Filters)\n",
    "\n",
    "### üìù Instructions:\n",
    "Run a complete RAG query - retrieval + LLM generation.\n",
    "\n",
    "### Watch for:\n",
    "1. üîç Documents retrieved from Milvus\n",
    "2. üí° API call to NetApp LLM\n",
    "3. üìù AI-generated answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb5ede12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ TEST 1: Basic Query\n",
      "================================================================================\n",
      "\\nüîç Retrieving for: 'What were NVIDIA's Q3 2023 revenue highlights?'\n",
      "   ‚úÖ Retrieved 5 documents\n",
      "   1. 2023 Q2 NVDA.pdf (Page 22)\n",
      "   2. 2023 Q3 NVDA.pdf (Page 22)\n",
      "   3. 2023 Q3 NVDA.pdf (Page 23)\n",
      "\\nüí° Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Answer received (257 chars)\n",
      "\\n================================================================================\\nüìù ANSWER:\\n================================================================================\n",
      "For Q3 2023 (three months ended Oct 29, 2023), NVIDIA reported $18.12B in revenue, up from $5.93B a year earlier. Segment mix: $14.65B from Compute & Networking and $3.48B from Graphics; by geography: U.S. $6.30B, Taiwan $4.33B, and China (incl. HK) $4.03B.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "print(\"=\"*80)\n",
    "print(\"üß™ TEST 1: Basic Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"What were NVIDIA's Q3 2023 revenue highlights?\",\n",
    "    \"context\": [],\n",
    "    \"answer\": \"\",\n",
    "    \"metadata_filter\": \"\",\n",
    "    \"retrieved_count\": 0\n",
    "})\n",
    "\n",
    "print(f\"\\\\n{'='*80}\\\\nüìù ANSWER:\\\\n{'='*80}\")\n",
    "print(result[\"answer\"])\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "158c339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ TEST 2: Filtered Query (AMZN Q1 2023)\n",
      "================================================================================\n",
      "\\nüîç Retrieving for: 'What were the key financial metrics?'\n",
      "   Filter: company == \"AMZN\" and year == 2023 and quarter == \"Q1\"\n",
      "   ‚úÖ Retrieved 5 documents\n",
      "   1. 2023 Q1 AMZN.pdf (Page 10)\n",
      "   2. 2023 Q1 AMZN.pdf (Page 28)\n",
      "   3. 2023 Q1 AMZN.pdf (Page 9)\n",
      "\\nüí° Generating answer...\n",
      "   ‚úÖ Answer received (456 chars)\n",
      "\\n================================================================================\\nüìù ANSWER:\\n================================================================================\n",
      "- Other operating expense (income), net: $249 million in Q1 2022 vs $223 million in Q1 2023; interest income: $108 million in Q1 2022 vs $611 million in Q1 2023.\n",
      "- Cash and marketable securities at fair value included cash of $10,968 million as of March 31, 2023 (vs $10,666 million at December 31, 2022), held primarily in AAA-rated money market funds, government and agency securities, other investment-grade securities, and marketable equity securities.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "print(\"=\"*80)\n",
    "print(\"üß™ TEST 2: Filtered Query (AMZN Q1 2023)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"What were the key financial metrics?\",\n",
    "    \"context\": [],\n",
    "    \"answer\": \"\",\n",
    "    \"metadata_filter\": 'company == \"AMZN\" and year == 2023 and quarter == \"Q1\"',\n",
    "    \"retrieved_count\": 0\n",
    "})\n",
    "\n",
    "print(f\"\\\\n{'='*80}\\\\nüìù ANSWER:\\\\n{'='*80}\")\n",
    "print(result[\"answer\"])\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 13: Helper Function\n",
    "\n",
    "### üìù Instructions:\n",
    "Create a simple function for easy querying.\n",
    "\n",
    "### Usage:\n",
    "```python\n",
    "# Simple\n",
    "answer = ask_question(\"Question?\")\n",
    "\n",
    "# With filter\n",
    "answer = ask_question(\"Question?\", 'company == \"NVDA\"')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f55512d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper function ready\n",
      "Usage: ask_question('What was revenue?', 'company == \"NVDA\"')\n"
     ]
    }
   ],
   "source": [
    "# Helper function\n",
    "def ask_question(question: str, filter_expr: str = \"\"):\n",
    "    print(f\"\\\\n‚ùì {question}\")\n",
    "    if filter_expr:\n",
    "        print(f\"üîç {filter_expr}\")\n",
    "    \n",
    "    result = app.invoke({\n",
    "        \"question\": question,\n",
    "        \"context\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"metadata_filter\": filter_expr,\n",
    "        \"retrieved_count\": 0\n",
    "    })\n",
    "    \n",
    "    print(f\"\\\\nüìù ANSWER:\\\\n{result['answer']}\\\\n{'='*80}\")\n",
    "    return result[\"answer\"]\n",
    "\n",
    "print(\"‚úÖ Helper function ready\")\n",
    "print(\"Usage: ask_question('What was revenue?', 'company == \\\"NVDA\\\"')\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 14: Try Your Own Query!\n",
    "\n",
    "### üìù Instructions:\n",
    "**Customize and run your own query.**\n",
    "\n",
    "Modify the variables below:\n",
    "- `my_question`: Your question about SEC filings\n",
    "- `my_filter`: Metadata filter (or leave empty)\n",
    "\n",
    "### Example filters:\n",
    "```python\n",
    "'company == \"NVDA\"'\n",
    "'company == \"AAPL\" and year == 2023'\n",
    "'quarter == \"Q3\" and year == 2023'\n",
    "'company in [\"NVDA\", \"INTC\"]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce35af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n‚ùì What was Microsoft's cloud revenue growth?\n",
      "üîç company == \"MSFT\" and year == 2023\n",
      "\\nüîç Retrieving for: 'What was Microsoft's cloud revenue growth?'\n",
      "   Filter: company == \"MSFT\" and year == 2023\n",
      "   ‚úÖ Retrieved 5 documents\n",
      "   1. 2023 Q3 MSFT.pdf (Page 34)\n",
      "   2. 2023 Q2 MSFT.pdf (Page 36)\n",
      "   3. 2023 Q1 MSFT.pdf (Page 38)\n",
      "\\nüí° Generating answer...\n",
      "   ‚úÖ Answer received (71 chars)\n",
      "\\nüìù ANSWER:\\nThe provided context does not specify Microsoft‚Äôs cloud revenue growth.\\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== CUSTOMIZE HERE ==========\n",
    "my_question = \"What was Microsoft's cloud revenue growth?\"\n",
    "my_filter = 'company == \"MSFT\" and year == 2023'\n",
    "# ====================================\n",
    "\n",
    "answer = ask_question(my_question, my_filter)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary\n",
    "\n",
    "### ‚úÖ Complete RAG System Built!\n",
    "\n",
    "**Components:**\n",
    "- Milvus vector database (127.0.0.1:19530)\n",
    "- HuggingFace embeddings (all-MiniLM-L6-v2)\n",
    "- LangChain Milvus integration\n",
    "- NetApp LLM (gpt-5 model)\n",
    "- LangGraph workflow orchestration\n",
    "\n",
    "**Workflow:**\n",
    "```\n",
    "Question ‚Üí Embedding ‚Üí Milvus Search (with filters) ‚Üí NetApp LLM ‚Üí Answer\n",
    "```\n",
    "\n",
    "**Data:**\n",
    "- 1,037 pages from 20 SEC filings\n",
    "- 5 companies: AAPL, AMZN, INTC, MSFT, NVDA\n",
    "- Time: 2022-2023\n",
    "\n",
    "**Answer location in API response:**\n",
    "```python\n",
    "response[\"choices\"][0][\"text\"]\n",
    "```\n",
    "\n",
    "### üìö Teaching Points\n",
    "\n",
    "**Key Concepts Covered:**\n",
    "1. Vector similarity search\n",
    "2. Metadata filtering\n",
    "3. State management in LangGraph\n",
    "4. LLM API integration\n",
    "5. Error handling\n",
    "\n",
    "**For Your Team:**\n",
    "- Parts 1-11: Core system setup\n",
    "- Parts 12-13: Hands-on practice\n",
    "- Modify Part 13 for experimentation\n",
    "\n",
    "### Next Steps:\n",
    "- Add conversation memory\n",
    "- Implement re-ranking\n",
    "- Build web UI (Streamlit)\n",
    "- Add response streaming\n",
    "\n",
    "**üéâ System ready for production use!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
